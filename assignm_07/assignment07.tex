\documentclass[fontsize=12pt,a4paper]{scrartcl}
 
% Das Prozent\item Zeichen leitet einen Kommentar ein,
% es hilft ebenso, im Text Leerzeichen zu unterbinden.
 
% fontsize=12pt  Schriftgroesse in 10, 11 oder 12 Punkt
% a4paper        Papierformat ist hier A4
% landscape      Querformat wird natÃƒÂ¼rlich unterstÃƒÂ¼tzt ;\item )
% parskip        Absatzabstand anstatt EinzÃƒÂ¼ge
% draft          Der Entwurfsmodus deckt SchwÃƒÂ¤chen auf
% {scrartcl}     Die Dokumentenklasse book, report, article
%                oder fÃƒÂ¼rs deutsche scrbook, scrreprt, scrartcl
 
%\usepackage[ngerman]{babel} % Deutsche Sprachanpassungen
\usepackage[T1]{fontenc}    % Silbentrennung bei Sonderzeichen
\usepackage[latin1]{inputenc} % Direkte Angabe von Umlauten im Dokument.
                            % Wenn Sie an einem Mac sitzen,verwenden
                            % Sie ggf. Ã¢Â€ÂžmacceÃ¢Â€Âœ anstatt Ã¢Â€Âžutf8Ã¢Â€Âœ.
 
\usepackage{textcomp}       % ZusÃƒÂ¤tzliche Symbolzeichen
\usepackage{siunitx}
\usepackage{amsmath}
\usepackage{listings}
\lstset{tabsize=4, showspaces=false}


\title{Machine Learning SS2013}
\subtitle{Ulrike von Luxburg \\ Assignment 07}
\author{Arne Schröder \and Falk Oswald \and Angel Bakardzhiev}
 
\date{\today}               % \today setzt das heutige Datum
 
\begin{document}
\maketitle                  % Titelei erzeugen
% \tableofcontents            % Inhaltsverzeichnis anlegen

 \section*{Exercise 1}
Für die Entscheidung zur Wahl eines Klassifikators spielen verschiedene Faktoren eine Rolle, die im Folgenden aufgelistet werden.

Indirekte Faktoren:
\begin{itemize}
\item Preis
\item Performance
\item Skalierung
\item Komplexität (der Benutzung)
\item Dokumentation
\end{itemize}

Direkte Faktoren:
\begin{itemize}
\item Gesamtqualität (geringe Fehlerquote)
\item Fehleranfälligkeit (bsp. outlier detection)
\item Einstellbarkeit (Geringe Komplexität bei der Findung der besten Einstellungen)
\item In Abhängigkeit von den Daten, einen passenden Klassifikator über den bias auswählen (ein linearer Klassifikator macht bspws. bei konzentrischen Daten keinen Sinn)
\end{itemize}

Setup zum Prüfen von Klassifikatoren
\begin{itemize} 
\item Zunächst repräsentative Daten erfassen
\item Immer gleiche Trainings\item  und Testdaten verwenden
\item Die Mächtigkeit der Tranings- und Testdaten und deren Verhältnis variieren
\item Möglichst viele (statistisch unabhängige) Trainings\item  und Testdaten
\item Sukzessive Erweiterung des Testsatzes um eventuelle Skalierungsfaktoren vorhersagen zu können
\end{itemize}

Evaluierung der Klassifikatoren nach
\begin{itemize} 
\item False positive/negative rate
\item Leistung (Zeit und Platzverbrauch)
\item Output der Interpretation des Algorithmus
\end{itemize}

\section*{Exercise 2}

\begin{enumerate}

\item \textbf{Selecting candidate classifiers: Consider at least three different classifiers}

Our classifiers:
\begin{itemize} 
\item kNN
\item SVM
\item LDA
\end{itemize}

For multiclass-classification the approaches one-vs-one and one-vs-all were used.

\item \textbf{Choosing datasets: You should use at least three different datasets.}

The datasets that we used:
\begin{itemize} 
\item USPS
\item Breast cancer
\item Random sample from Statlog Shuttle dataset

(http://archive.ics.uci.edu/ml/datasets/Statlog+\%28Shuttle\%29)
\end{itemize}

\item \textbf{Run the algorithms on the data sets and compare the results.}

For the smallest data set, the cancer data set, SVM and LDA perform reasonably well with an error rate of 3 \%, whereas kNN outperforms theses with an error rate of 2 \%.

The other data sets did not perform acceptably with SVM, so we only compared LDA with kNN. With the shuttle data set, kNN had an error rate of 0.4 \%, whereas LDA had an error rate of 4.8 \% and 10.8 \% with one-vs-one and one-vs-all respectively. The USPS data set showed similar error rates for LDA: had an error rate of 11.1 \% and 14.7 \% with one-vs-one and one-vs-all respectively, whereas kNN failed to run because the datasets were too large.

\item \textbf{Try to understand the results and the data.}

The better results for kNN do not surprise too much in the first place as SVM and LDA try to differentiate two classes by a hyperplane, whereas kNN does not have such a restriction and is able to differentiate much more complex classes.

\end{enumerate}

\end{document}
